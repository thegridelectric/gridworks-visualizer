{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b24b50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome to the FLO report generator!\n",
      "\n",
      "Generating report for oak from 2026-01-27 20:00:00-05:00 to 2026-01-31 07:00:00-05:00\n",
      "\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-28 09:57:08.975000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-28 10:57:09.182000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-28 11:57:32.032000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-28 12:57:52.074000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-28 13:57:52.381000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-28 14:57:51.754000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-28 15:57:51.151000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-28 16:57:50.698000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-28 17:57:50.129000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-28 18:57:49.546000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-28 19:57:49.018000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-28 20:57:48.980000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-28 21:57:49.400000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-28 22:57:48.760000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-28 23:57:48.756000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-29 00:57:48.129000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-29 01:57:47.554000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-29 02:57:47.698000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-29 03:57:47.093000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-29 04:57:47.878000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-29 05:57:17.486000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-29 06:57:17.975000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-29 07:57:17.945000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-29 08:57:18.080000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-29 09:57:14.021000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-29 10:57:13.960000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-29 11:57:13.999000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-29 12:57:14.973000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-29 13:57:15.099000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-29 14:57:14.783000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-29 15:57:15.327000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-29 16:57:15.743000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-29 17:57:15.515000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-29 18:57:15.106000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-29 19:57:15.160000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-29 20:57:15.248000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-29 21:57:14.630000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-29 22:57:14.028000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-29 23:57:13.773000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-30 00:57:14.541000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-30 01:57:14.058000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-30 02:57:14.353000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-30 03:57:14.569000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-30 04:57:14.039000-05:00\n",
      "Adding message from hw1.isone.me.versant.keene.oak at 2026-01-30 05:57:14.260000-05:00\n",
      "Found 91 messages and 45 of them at minute 57\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-31 13:18:19,056 [INFO] gridflo.flo: Launching flo for hw1.isone.me.versant.keene.oak.scada\n",
      "2026-01-31 13:18:19,057 [WARNING] gridflo.flo: glitch to hw1.isone.me.versant.keene.oak.scada: {'TypeName': 'glitch', 'Version': '001', 'FromGNodeAlias': 'hw1.isone.gwflo1', 'AboutGNodeAlias': 'hw1.isone.me.versant.keene.oak.scada', 'Level': 'Critical', 'Summary': 'Supergraph load failure', 'Details': \"Supergraph meta data not found at  /Users/thomas/.config/gridworks/gridflo/supergraph_meta_380418a8.json with params {'TypeName': 'winter.oak.supergraph.params', 'Version': '001', 'NumLayers': 24, 'StorageVolumeGallons': 360, 'HpMaxElecKw': 11.0, 'CopIntercept': 1.02, 'CopOatCoeff': 0.0257, 'CopMin': 1.4, 'CopMinOatF': 15.0, 'ConstantDeltaT': 20}\", 'CreatedMs': 1769861899057}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52 hourly records for oak (hp_elec_in, hp_heat_out)\n"
     ]
    },
    {
     "ename": "NeedsSupergraph",
     "evalue": "Supergraph meta data not found at  /Users/thomas/.config/gridworks/gridflo/supergraph_meta_380418a8.json with params {'TypeName': 'winter.oak.supergraph.params', 'Version': '001', 'NumLayers': 24, 'StorageVolumeGallons': 360, 'HpMaxElecKw': 11.0, 'CopIntercept': 1.02, 'CopOatCoeff': 0.0257, 'CopMin': 1.4, 'CopMinOatF': 15.0, 'ConstantDeltaT': 20}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNeedsSupergraph\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 127\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, flo_params_msg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(flo_params_messages):\n\u001b[1;32m    126\u001b[0m     flo_params \u001b[38;5;241m=\u001b[39m FloParamsHouse0(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mflo_params_msg\u001b[38;5;241m.\u001b[39mpayload)\n\u001b[0;32m--> 127\u001b[0m     g \u001b[38;5;241m=\u001b[39m \u001b[43mFlo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflo_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     g\u001b[38;5;241m.\u001b[39msolve_dijkstra()\n\u001b[1;32m    129\u001b[0m     g\u001b[38;5;241m.\u001b[39mgenerate_recommendation(flo_params\u001b[38;5;241m.\u001b[39mto_bytes())\n",
      "File \u001b[0;32m~/github/gridworks-innovations/gridworks-flo/src/gridflo/flo.py:61\u001b[0m, in \u001b[0;36mFlo.__init__\u001b[0;34m(self, flo_params_bytes)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupergraph_meta_path \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mconfig_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupergraph_meta_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupergraph_params\u001b[38;5;241m.\u001b[39mhash\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m )\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (NeedsSupergraph, InvalidSupergraph) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(\n\u001b[1;32m     64\u001b[0m         Glitch(\n\u001b[1;32m     65\u001b[0m             from_g_node_alias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mG_NODE_ALIAS,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m         to_alias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflo_params\u001b[38;5;241m.\u001b[39mg_node_alias,\n\u001b[1;32m     72\u001b[0m     )\n",
      "File \u001b[0;32m~/github/gridworks-innovations/gridworks-flo/src/gridflo/flo.py:112\u001b[0m, in \u001b[0;36mFlo.initialize_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03mInitialize the graph: load the supergraph and then populate nodes and\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03medge weights\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m    GraphInitializationError: If the supergraph doesn't initialize\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading supergraph from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupergraph_meta_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_supergraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# If we got here, loading the supergraph worked\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/github/gridworks-innovations/gridworks-flo/src/gridflo/flo.py:153\u001b[0m, in \u001b[0;36mFlo.load_supergraph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03mLoads self.supergraph\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m    InvalidSupergraph: If JSON or ASL validation fails\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupergraph_meta_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NeedsSupergraph(\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupergraph meta data not found at  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupergraph_meta_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m with params \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupergraph_params\u001b[38;5;241m.\u001b[39mto_dict()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# Load and validate the small ASL metadata file\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     meta_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupergraph_meta_path\u001b[38;5;241m.\u001b[39mread_text())\n",
      "\u001b[0;31mNeedsSupergraph\u001b[0m: Supergraph meta data not found at  /Users/thomas/.config/gridworks/gridflo/supergraph_meta_380418a8.json with params {'TypeName': 'winter.oak.supergraph.params', 'Version': '001', 'NumLayers': 24, 'StorageVolumeGallons': 360, 'HpMaxElecKw': 11.0, 'CopIntercept': 1.02, 'CopOatCoeff': 0.0257, 'CopMin': 1.4, 'CopMinOatF': 15.0, 'ConstantDeltaT': 20}"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "import pendulum\n",
    "from sqlalchemy import asc, cast\n",
    "from sqlalchemy import create_engine, select, BigInteger, MetaData, Table\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from config import Settings\n",
    "from models import MessageSql\n",
    "from gridflo.asl.types import FloParamsHouse0\n",
    "from gridflo.dijkstra_types import DNode, DEdge\n",
    "from gridflo import Flo, DGraphVisualizer, DNodeVisualizer\n",
    "from gridflo.asl.types import WinterOakSupergraphParams\n",
    "from gridflo.supergraph_generator import WinterOakSupergraphParams\n",
    "from gridflo.dijkstra_types import DNode\n",
    "import gc\n",
    "import os\n",
    "import shutil\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.pdfgen import canvas\n",
    "from PIL import Image\n",
    "\n",
    "print(\"\\nWelcome to the FLO report generator!\\n\")\n",
    "house_alias = input(\"Enter house alias: \")\n",
    "if not house_alias:\n",
    "    print(\"House alias is required\")\n",
    "    exit()\n",
    "\n",
    "now = pendulum.now(tz='America/New_York')\n",
    "yesterday_8pm = now.subtract(days=1).set(hour=20, minute=0, second=0, microsecond=0)\n",
    "\n",
    "start_input = input(\"Enter start year, month, day, hour (default: yesterday 8pm): \")\n",
    "if start_input and len(start_input.split(',')) == 4:\n",
    "    START_YEAR, START_MONTH, START_DAY, START_HOUR = start_input.split(',')\n",
    "    START_YEAR, START_MONTH, START_DAY, START_HOUR = int(START_YEAR), int(START_MONTH), int(START_DAY), int(START_HOUR)\n",
    "else:\n",
    "    START_YEAR, START_MONTH, START_DAY, START_HOUR = yesterday_8pm.year, yesterday_8pm.month, yesterday_8pm.day, yesterday_8pm.hour\n",
    "\n",
    "end_input = input(\"Enter end year, month, day, hour (default: now): \")\n",
    "if end_input and len(end_input.split(',')) == 4:\n",
    "    END_YEAR, END_MONTH, END_DAY, END_HOUR = end_input.split(',')\n",
    "    END_YEAR, END_MONTH, END_DAY, END_HOUR = int(END_YEAR), int(END_MONTH), int(END_DAY), int(END_HOUR)\n",
    "else:\n",
    "    END_YEAR, END_MONTH, END_DAY, END_HOUR = now.year, now.month, now.day, now.hour\n",
    "\n",
    "start_time = pendulum.datetime(START_YEAR, START_MONTH, START_DAY, START_HOUR, tz='America/New_York')\n",
    "end_time = pendulum.datetime(END_YEAR, END_MONTH, END_DAY, END_HOUR, tz='America/New_York')\n",
    "\n",
    "# TEMPORARY\n",
    "# house_alias = \"oak\"\n",
    "# start_time = pendulum.datetime(2026, 1, 20, 20, tz='America/New_York')\n",
    "# end_time = pendulum.datetime(2026, 1, 20, 22, tz='America/New_York')\n",
    "\n",
    "start_ms = start_time.timestamp()*1000\n",
    "end_ms = end_time.timestamp()*1000\n",
    "print(f\"Generating report for {house_alias} from {start_time} to {end_time}\\n\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Part 1: Find FLO params messages\n",
    "# ---------------------------------------------------\n",
    "\n",
    "stmt = select(MessageSql).filter(\n",
    "    MessageSql.message_type_name == \"flo.params.house0\",\n",
    "    MessageSql.from_alias == f\"hw1.isone.me.versant.keene.{house_alias}\",\n",
    "    MessageSql.message_persisted_ms <= cast(int(end_ms+10*60*1000), BigInteger),\n",
    "    MessageSql.message_persisted_ms >= cast(int(start_ms-10*60*1000), BigInteger),\n",
    ").order_by(asc(MessageSql.message_persisted_ms))\n",
    "\n",
    "settings = Settings(_env_file=dotenv.find_dotenv())\n",
    "engine = create_engine(settings.db_url_no_async.get_secret_value())\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "result = session.execute(stmt)\n",
    "messages = result.scalars().all()\n",
    "\n",
    "flo_params_messages = []\n",
    "for m in messages:\n",
    "    if pendulum.from_timestamp(m.message_persisted_ms/1000, tz='America/New_York').minute == 57:\n",
    "        print(f\"Adding message from {m.from_alias} at {pendulum.from_timestamp(m.message_persisted_ms/1000, tz='America/New_York')}\")\n",
    "        flo_params_messages.append(m)\n",
    "\n",
    "print(f\"Found {len(messages)} messages and {len(flo_params_messages)} of them at minute 57\\n\")\n",
    "\n",
    "session.close()\n",
    "engine.dispose()\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Part 2: Find hourly data: hp_elec_in, hp_heat_out\n",
    "# ---------------------------------------------------\n",
    "# Use backoffice DB (same as get_electricity_use in visualizer_api.py)\n",
    "gbo_engine = create_engine(settings.gbo_db_url_no_async.get_secret_value())\n",
    "hourly_electricity = Table('hourly_electricity', MetaData(), autoload_with=gbo_engine)\n",
    "GboSession = sessionmaker(bind=gbo_engine)\n",
    "gbo_session = GboSession()\n",
    "stmt_hourly = select(hourly_electricity).where(\n",
    "    hourly_electricity.c.short_alias == house_alias,\n",
    "    hourly_electricity.c.hour_start_s >= int(start_ms // 1000),\n",
    "    hourly_electricity.c.hour_start_s <= int(end_ms // 1000),\n",
    ").order_by(asc(hourly_electricity.c.hour_start_s))\n",
    "hourly_records = gbo_session.execute(stmt_hourly).all()\n",
    "# Build lists: one row per hour (hp_elec_in may be stored as hp_kwh_el in DB)\n",
    "hourly_hour_start_s = []\n",
    "hourly_hp_elec_in = []\n",
    "hourly_hp_heat_out = []\n",
    "for rec in hourly_records:\n",
    "    hourly_hour_start_s.append(rec.hour_start_s)\n",
    "    hourly_hp_elec_in.append(getattr(rec, 'hp_elec_in', getattr(rec, 'hp_kwh_el', 0)))\n",
    "    hourly_hp_heat_out.append(getattr(rec, 'hp_kwh_th', getattr(rec, 'hp_heat_out', 0)))\n",
    "print(f\"Found {len(hourly_records)} hourly records for {house_alias} (hp_elec_in, hp_heat_out)\")\n",
    "gbo_session.close()\n",
    "gbo_engine.dispose()\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Part 3: Generate plots in plots/ directory\n",
    "# ---------------------------------------------------\n",
    "\n",
    "if os.path.exists('plots'):\n",
    "    shutil.rmtree('plots')\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "\n",
    "true_init_energy, true_final_energy = [0]*len(flo_params_messages), [0]*len(flo_params_messages)\n",
    "heat_to_store_expected = []\n",
    "heat_from_hp_expected = []\n",
    "true_initial_states, true_final_states = [None]*len(flo_params_messages), [None]*len(flo_params_messages)\n",
    "\n",
    "for i, flo_params_msg in enumerate(flo_params_messages):\n",
    "    flo_params = FloParamsHouse0(**flo_params_msg.payload)\n",
    "    g = Flo(flo_params.to_bytes())\n",
    "    g.solve_dijkstra()\n",
    "    g.generate_recommendation(flo_params.to_bytes())\n",
    "    v = DGraphVisualizer(g)\n",
    "    v.plot(show=False,save_as=f'plots/flo{i+1}_graph.png')\n",
    "    v.plot_pq_pairs(save_as=f'plots/flo{i+1}_pq_pairs.png')\n",
    "    initial_node_edge: DEdge = [e for e in g.bid_edges[g.initial_node] if e.head == g.initial_node.next_node][0]\n",
    "    hp_heat_out_expected = initial_node_edge.hp_heat_out\n",
    "    heat_to_store_expected.append(hp_heat_out_expected - initial_node_edge.load_and_losses)\n",
    "    heat_from_hp_expected.append(hp_heat_out_expected)\n",
    "\n",
    "    winter_oak_supergraph_params = WinterOakSupergraphParams(\n",
    "        num_layers=flo_params.num_layers,\n",
    "        storage_volume_gallons=flo_params.storage_volume_gallons,\n",
    "        hp_max_elec_kw=flo_params.hp_max_elec_kw,\n",
    "        cop_intercept=flo_params.cop_intercept,\n",
    "        cop_oat_coeff=flo_params.cop_oat_coeff,\n",
    "        cop_min=flo_params.cop_min,\n",
    "        cop_min_oat_f=flo_params.cop_min_oat_f,\n",
    "        constant_delta_t=flo_params.constant_delta_t,\n",
    "    )\n",
    "    \n",
    "    true_initial_node = DNode(\n",
    "        top_temp=flo_params.initial_top_temp_f,\n",
    "        middle_temp=flo_params.initial_middle_temp_f,\n",
    "        bottom_temp=flo_params.initial_bottom_temp_f,\n",
    "        thermocline1=flo_params.initial_thermocline_1,\n",
    "        thermocline2=flo_params.initial_thermocline_2,\n",
    "        parameters=winter_oak_supergraph_params,\n",
    "    )\n",
    "    true_initial_states[i] = true_initial_node\n",
    "\n",
    "    true_init_energy[i] = true_initial_node.energy\n",
    "    true_init_node = DNodeVisualizer(true_initial_node, 'true_initial')\n",
    "    init_node = DNodeVisualizer(g.initial_node, 'initial')\n",
    "    expected_node = DNodeVisualizer(g.initial_node.next_node, 'expected')\n",
    "    true_init_node.plot(save_as=f'plots/flo{i+1}_true_initial.png')\n",
    "    init_node.plot(save_as=f'plots/flo{i+1}_initial.png')\n",
    "    expected_node.plot(save_as=f'plots/flo{i+1}_expected.png')\n",
    "    if i!=0:\n",
    "        true_final_node = DNode(\n",
    "            top_temp=flo_params.initial_top_temp_f,\n",
    "            middle_temp=flo_params.initial_middle_temp_f,\n",
    "            bottom_temp=flo_params.initial_bottom_temp_f,\n",
    "            thermocline1=flo_params.initial_thermocline_1,\n",
    "            thermocline2=flo_params.initial_thermocline_2,\n",
    "            parameters=winter_oak_supergraph_params,\n",
    "        )\n",
    "        true_final_states[i-1] = true_final_node\n",
    "        true_final_energy[i-1] = true_final_node.energy\n",
    "        true_final_node = DNodeVisualizer(true_final_node, 'true_final')\n",
    "        true_final_node.plot(save_as=f'plots/flo{i}_true_final.png')\n",
    "        final_node = DNodeVisualizer(g.initial_node, 'final')\n",
    "        final_node.plot(save_as=f'plots/flo{i}_final.png')\n",
    "\n",
    "    del g, v, init_node, expected_node\n",
    "    gc.collect()\n",
    "\n",
    "heat_to_store_true = [round(final-init, 2) for final, init in zip(true_final_energy, true_init_energy)]\n",
    "\n",
    "# Save to local pickle files\n",
    "import pickle\n",
    "with open(\"true_initial_states.pkl\", \"wb\") as f:\n",
    "    pickle.dump(true_initial_states, f)\n",
    "with open(\"true_final_states.pkl\", \"wb\") as f:\n",
    "    pickle.dump(true_final_states, f)\n",
    "with open(\"heat_to_store_true.pkl\", \"wb\") as f:\n",
    "    pickle.dump(heat_to_store_true, f)\n",
    "with open(\"flo_params_messages.pkl\", \"wb\") as f:\n",
    "    pickle.dump(flo_params_messages, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd07825b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
